{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download wave data from the AWS bucket\n",
    "Joshua Simmons 2022\n",
    "\n",
    "Example code for using Google Colab to download Hsig data for our time period of interest from the AWS bucket."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Connect to AWS and load the data\n",
    "\n",
    "See example [here](https://github.com/planet-os/notebooks/blob/master/aws/era5-s3-via-boto.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If using colab then:\n",
    "!pip install xarray dask[complete] pandas intake-esm xmip cftime gcsfs s3fs\n",
    "!pip install --upgrade requests==2.26.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade xarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to your google drive to download data to a folder\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/content/drive/My Drive/colab_connect/era5/')\n",
    "\n",
    "import s3fs \n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "\n",
    "s3_loc = 's3://era5-pds/{}/{}/data/significant_height_of_wind_and_swell_waves.nc'\n",
    "\n",
    "# get the data\n",
    "start_year = 1985\n",
    "end_year = 2022\n",
    "\n",
    "get_years = np.arange(start_year, end_year+1, 1)\n",
    "get_months = ['{:02.0f}'.format(_) for _ in np.arange(1, 13, 1)]\n",
    "\n",
    "fs = s3fs.S3FileSystem(anon=True)\n",
    "\n",
    "lat_sel = -28.0\n",
    "lon_sel = 153.5\n",
    "\n",
    "# -27.0,\n",
    "# 153.5,\n",
    "\n",
    "ll_sel = zip(\n",
    "    [-28.0,-29.0,-30.0,-31.0,-32.0,-33.0,-34.0,-35.0,-36.0,-37.0], \n",
    "    [153.5,153.5,153.5,153.5,153.0,152.0,151.5,151.0,150.5,150.0]\n",
    ")\n",
    "\n",
    "# this_year = get_years[0]\n",
    "for this_year in get_years:\n",
    "    for this_month in get_months:\n",
    "        with fs.open(s3_loc.format(this_year, this_month)) as f:\n",
    "            dataset = xr.open_dataset(\n",
    "                f, \n",
    "                engine='h5netcdf',\n",
    "                chunks={'time0': 1000, 'lat_ocean': 60, 'lon_ocean': 60}\n",
    "            )\n",
    "            dataset.sel(\n",
    "                lat_ocean=[-27.0,-28.0,-29.0,-30.0,-31.0,-32.0,-33.0,-34.0,-35.0,-36.0,-37.0], \n",
    "                lon_ocean=[153.5,153.5,153.5,153.5,153.5,153.0,152.0,151.5,151.0,150.5,150.0],\n",
    "            ).to_dataframe().to_csv('era5_{}{}_{}.csv'.format(this_year,this_month,'bulk'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now convert the downloaded data into manageable chunks\n",
    "Can do this locally.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loc = 'data/waves/raw'\n",
    "fns = glob.glob(os.path.join(data_loc, '*.csv'))\n",
    "\n",
    "# df = pd.concat([pd.read_csv(fn) for fn in fns])\n",
    "df = pd.read_csv(fns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ll_sel = zip(\n",
    "    [-27.0,-28.0,-29.0,-30.0,-31.0,-32.0,-33.0,-34.0,-35.0,-36.0,-37.0], \n",
    "    [153.5,153.5,153.5,153.5,153.5,153.0,152.0,151.5,151.0,150.5,150.0]\n",
    ")\n",
    "\n",
    "for lat_sel, lon_sel in ll_sel:\n",
    "    df = pd.concat([pd.read_csv(fn).query('lat_ocean == {} & lon_ocean == {}'.format(lat_sel,lon_sel)).set_index('time0').drop(columns=['lat_ocean', 'lon_ocean']).drop_duplicates() for fn in fns])\n",
    "    df.to_csv('data/waves/era5_{}_{}.csv'.format(lat_sel,lon_sel))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87fbea7b3721842a93ed4da8a1ac4b18f42b1eaaedefc3a2702202c09bf233e1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
